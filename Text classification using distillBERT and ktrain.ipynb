{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88161ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece] -q "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e4d57",
   "metadata": {},
   "source": [
    "DATASET DESCRIPTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "647d156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0d05dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the train and test sets #For my purpose I am considering 5 news categories for classification\n",
    "\n",
    "categories=['alt.atheism','comp.graphics','soc.religion.christian','rec.sport.hockey','sci.space']\n",
    "\n",
    "train=fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=50)\n",
    "test=fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e85299b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train data: 2856\n",
      "Size of test data: 1899\n"
     ]
    }
   ],
   "source": [
    "print('Size of train data:',len(train['data']))\n",
    "print('Size of test data:',len(test['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa8091de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes ['alt.atheism', 'comp.graphics', 'rec.sport.hockey', 'sci.space', 'soc.religion.christian']\n"
     ]
    }
   ],
   "source": [
    "print('Classes',train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69cd0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into train test \n",
    "\n",
    "x_train=train.data\n",
    "y_train=train.target\n",
    "x_test=test.data\n",
    "y_test=test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38c78707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.space\n",
      "\n",
      " \n",
      "From: thomsonal@cpva.saic.com\n",
      "Subject: What counntries do space surveillance?\n",
      "Organization: Science Applications Int'l Corp./San Diego\n",
      "Lines: 111\n",
      "\n",
      "      Ethnocentric USian that I am, I've assumed that we and the\n",
      "xUSSR were the only countries with significant capabilities to track\n",
      "non-cooperative objects in low Earth orbit. Grazing in a couple of \n",
      "databases recently,  I found that Japan has some optical capabilities\n",
      "along this line, and also uses a radar designed for other purposes\n",
      "for orbital debris surveys (it isn't clear whether the radar can \n",
      "determine orbital elements for the objects it detects). Abstracts of \n",
      "the articles are appended. \n",
      "\n",
      "\n",
      "    This leads to the more general question: do yet other people than \n",
      "the US, Russia, and Japan do space surveillance, and if so, how and \n",
      "why? \n",
      "\n",
      "Allen Thomson              SAIC                        McLean, VA, USA\n",
      "-----------------------------------------------------------------------\n",
      "                         ABSTRACTS\n",
      "\n",
      "Optical tracking of the experimental geodetic satellite (EGS)\n",
      "TAKABE, MASAO; ITABE, TOSHIKAZU; ARUGA, TADASHI\n",
      "Radio Research Laboratory, Review (ISSN 0033-801X), vol. 34,\n",
      "March 1988, p. 23-34. In Japanese, with abstract in English.\n",
      "     This paper reports the optical tracking results of EGS\n",
      "(experimental geodetic satellite) which was launched on August 13,\n",
      "1986, by NASDA. The EGS optical tracking experiment process and an\n",
      "outline of the Radio Research Laboratory (RRL) optical ground       <----\n",
      "station are discussed. A star tracking technique for optical\n",
      "equipment calibration and satellite tracking technique for orbit\n",
      "prediction improvement are also described. The accuracy of EGS\n",
      "tracking data obtained by RRL at the request of NASDA is also\n",
      "discussed. In addition, it is briefly demonstrated that the\n",
      "position of the Japanese amateur satellite (JAS-1) which was\n",
      "launched with the EGS, was accurately determined by means of a      <----\n",
      "satellite tracking video. It is clear from this experiment that     <----\n",
      "optical observation data (i.e., satellite direction data) are very  <----\n",
      "useful for satellite orbit determination during initial launch      <----\n",
      "stages. Furthermore, the results confirm the effectivenes of these  <----\n",
      "two satellite optical tracking techniques.                          <----\n",
      "\n",
      "\n",
      "MU radar measurements of orbital debris\n",
      "SATO, TORU; KAYAMA, HIDETOSHI; FURUSAWA, AKIRA; KIMURA, IWANE\n",
      "(Kyoto University, Japan)\n",
      "AIAA, NASA, and DOD, Orbital Debris Conference: Technical Issues and \n",
      "Future Directions, Baltimore, MD, Apr. 16-19, 1990. 10 p. \n",
      "RPN: AIAA PAPER 90-1343\n",
      "     Distributions of orbital debris versus height and scattering cross \n",
      "section are determined from a series of observations made with a high-\n",
      "power VHF Doppler radar (MU radar) of Japan. An automated data \n",
      "processing algorithm has been developed to discriminate echoes of \n",
      "orbiting objects from those of undesired signals such as meteor trail \n",
      "echoes or lightning atmospherics. Although the results are preliminary, \n",
      "they showed good agreement with those from NORAD tracking radar      <----\n",
      "observations using a much higher frequency. It is found that the     <----\n",
      "collision frequency of a Space Station of 1 km x 1 km size at an \n",
      "altitude of 500 km with orbiting debris is expected to be as high as \n",
      "once per two years. \n",
      "\n",
      "\n",
      "Monitoring of the MU radar antenna pattern by Satellite Ohzora (EXOS-C)\n",
      "SATO, T.; INOOKA, Y.; FUKAO, S. (Kyoto Univ., Japan); KATO, S.\n",
      "Kyoto Univ., Uji (Japan). Radio Atmospheric Science Center.\n",
      "In International Council of Scientific Unions, Middle Atmosphere Program.\n",
      "Handbook for MAP, Vol. 20 5 p\n",
      "Publication Date: Jun. 1986\n",
      "      As the first attempt among MST (mesosphere stratosphere \n",
      "troposphere) type radars, the MU (middle and upper atmosphere) radar \n",
      "features an active phased array system. Unlike the conventional large \n",
      "VHF radars, in which output power of a large vacuum tube is distributed \n",
      "to individual antenna elements, each of 475 solid state power amplifier \n",
      "feeds each antenna element. This system configuration enables very fast \n",
      "beam steering as well as various flexible operations by dividing the \n",
      "antenna into independent subarrays, because phase shift and signal \n",
      "division/combination are performed at a low signal level using \n",
      "electronic devices under control of a computer network. The antenna \n",
      "beam can be switched within 10 microsec to any direction within the \n",
      "zenith angle of 30 deg. Since a precise phase alignment of each element \n",
      "is crucial to realize the excellent performance of this system, careful \n",
      "calibration of the output phase of each power amplifier and antenna \n",
      "element was carried out. Among various aircraft which may be used for \n",
      "this purpose artificial satellites have an advantage of being able to \n",
      "make a long term monitoring with the same system. An antenna pattern \n",
      "monitoring system for the MU radar was developed using the scientific \n",
      "satellite OHZORA (EXOS-C). A receiver named MUM (MU radar antenna \n",
      "Monitor) on board the satellite measures a CW signal of 100 to 400 \n",
      "watts transmitted from the MU radar. The principle of the measurement \n",
      "and results are discussed.\n",
      "\n",
      "\n",
      "Equatorial radar system\n",
      "FUKAO, SHOICHIRO;  TSUDA, TOSHITAKA; SATO, TORU; KATO, SUSUMU\n",
      "(Kyoto University, Uji, Japan)\n",
      "(COSPAR, IAGA, SCOSTEP, et al., Plenary Meeting, 27th,\n",
      "Workshops and Symposium on the Earth's Middle Atmosphere,\n",
      "Espoo, Finland, July 18-29, 1988) Advances in Space Research\n",
      "(ISSN 0273-1177), vol. 10, no. 10, 1990, p. 151-154.\n",
      "     A large clear air radar with the sensitivity of an incoherent \n",
      "scatter radar for observing the whole equatorial atmosphere up to 1000 \n",
      "km altitude is now being designed in Japan. The radar will be built in \n",
      "Pontianak, West Kalimantan, Indonesia (0.03 deg N, 109.29 deg E). The \n",
      "system is a 47-MHz monostatic Doppler radar with an active phased array \n",
      "configuration similar to that of the MU radar in Japan, which has been \n",
      "in successful operation since 1983. It will have a PA product of about \n",
      "3 x 10 to the 9th W sq m (P = average transmitter power, A = effective \n",
      "antenna aperture) with a sensitivity of approximately 10 times that of \n",
      "the MU radar. This system configuration enables pulse-to-pulse beam \n",
      "steering within 20 deg from the zenith. As is the case of the MU radar, \n",
      "a variety of operations will be made feasible under the supervision of \n",
      "the radar controller. A brief description of the system configuration \n",
      "is presented. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at the data\n",
    "\n",
    "print(train.target_names[y_train[0]])\n",
    "print(\"\\n \")\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62159833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrainNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading ktrain-0.33.2.tar.gz (25.3 MB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from ktrain) (1.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from ktrain) (3.5.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from ktrain) (1.4.2)\n",
      "Collecting fastprogress>=0.1.21\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from ktrain) (2.27.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from ktrain) (1.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from ktrain) (21.3)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "Collecting cchardet\n",
      "  Downloading cchardet-2.1.7-cp39-cp39-win_amd64.whl (115 kB)\n",
      "Requirement already satisfied: chardet in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from ktrain) (4.0.0)\n",
      "Collecting syntok>1.3.3\n",
      "  Downloading syntok-1.4.4-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: transformers>=4.17.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from ktrain) (4.26.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from ktrain) (0.1.97)\n",
      "Collecting keras_bert>=0.86.0\n",
      "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
      "Collecting whoosh\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras_bert>=0.86.0->ktrain) (1.21.5)\n",
      "Collecting keras-transformer==0.40.0\n",
      "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
      "Collecting keras-pos-embd==0.13.0\n",
      "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
      "Collecting keras-multi-head==0.29.0\n",
      "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
      "Collecting keras-layer-normalization==0.16.0\n",
      "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
      "Collecting keras-position-wise-feed-forward==0.8.0\n",
      "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
      "Collecting keras-embed-sim==0.10.0\n",
      "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
      "Collecting keras-self-attention==0.51.0\n",
      "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (4.25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=1.0.1->ktrain) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->ktrain) (1.16.0)\n",
      "Requirement already satisfied: regex>2016 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from syntok>1.3.3->ktrain) (2022.3.15)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers>=4.17.0->ktrain) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers>=4.17.0->ktrain) (0.12.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers>=4.17.0->ktrain) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers>=4.17.0->ktrain) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers>=4.17.0->ktrain) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.17.0->ktrain) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers>=4.17.0->ktrain) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->ktrain) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->ktrain) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->ktrain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->ktrain) (3.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn->ktrain) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn->ktrain) (2.2.0)\n",
      "Building wheels for collected packages: ktrain, keras-bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, jieba, langdetect\n",
      "  Building wheel for ktrain (setup.py): started\n",
      "  Building wheel for ktrain (setup.py): finished with status 'done'\n",
      "  Created wheel for ktrain: filename=ktrain-0.33.2-py3-none-any.whl size=25313841 sha256=c23b06e30d6df5324b5e10b7fc0aac19f4e3d13b99a42699480f6f66b63706f0\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\95\\20\\1f\\309ffe6e6ff88187ad19e1bc684dcaf27d67d886c5315a6203\n",
      "  Building wheel for keras-bert (setup.py): started\n",
      "  Building wheel for keras-bert (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33517 sha256=135ffcd3fb8eb465336097a87ff4ceec499c096ecb9f61ede9a5784f31e3f066\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\4e\\26\\24\\14ecbc0166364db7f5500164b7d796263cf3cd10c57e892180\n",
      "  Building wheel for keras-transformer (setup.py): started\n",
      "  Building wheel for keras-transformer (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12305 sha256=6dbb39bda2070d462beba67b4f9e530014956e97c27f6dbe7060b77ed94e484b\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\5e\\d6\\d1\\c588c3b2b112c8f1173934995836ab2f2de8323cce99fa998f\n",
      "  Building wheel for keras-embed-sim (setup.py): started\n",
      "  Building wheel for keras-embed-sim (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3960 sha256=ca76dcc1b4536f0cedb4f8218b8700fc48ed42d8640b183bc7184dd83f64829c\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\cb\\25\\02\\4bb438785ef9c10d07f6b3519f080b38917153fdac3108d738\n",
      "  Building wheel for keras-layer-normalization (setup.py): started\n",
      "  Building wheel for keras-layer-normalization (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4668 sha256=e3515ffa2e2e17da235cc37b3e4112cfd2a220652a7fde759ea2f64bad7a8232\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\c1\\df\\15\\a88cdf68ce687574649f65063a743123e1bee79932b6eea3b6\n",
      "  Building wheel for keras-multi-head (setup.py): started\n",
      "  Building wheel for keras-multi-head (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14993 sha256=7114a79292525075721bbd91f8602334b77602544c844f01422669d172b95de7\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\b3\\85\\50\\f232cac81ed1eb4dc20db31a9d1f4a8a1a8c696d4d27bff442\n",
      "  Building wheel for keras-pos-embd (setup.py): started\n",
      "  Building wheel for keras-pos-embd (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6962 sha256=5abfe7ee56468d627a57d9e945bc6bb89f5a7eeab5e828ea64420849088f7e20\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\f5\\8c\\9a\\917bf72d493e084ca1706a02679185789c2715f50770d8c987\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py): started\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4983 sha256=8d24f0bc59d8f86a107cfdd44c6d23050f92cb255ee5730f793ab04d043c42c4\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\20\\36\\25\\efb605ab1742a179274a6f7cb113da1c6758f45e212b59bb4d\n",
      "  Building wheel for keras-self-attention (setup.py): started\n",
      "  Building wheel for keras-self-attention (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=3555f3ea8aae8f614fcfc8f7ac91854a52301884e4719eafb86a0edea455afce\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\78\\c1\\84\\b83a2fd6f1d63e136cba74bac4126bee3b8705eef6486635fd\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=c64201fcb7bdc77d7311efd0e5c7af08e338cbeacdf8a2d1e7cb45a73e619f0a\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\7d\\74\\cf\\08c94db4b784e2c1ef675a600b7b5b281fd25240dcb954ee7e\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=2af60671eef519c3dd3da53db5dcfd6871afd41f22ac7394bd25b34d89954751\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\d1\\c1\\d9\\7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "Successfully built ktrain keras-bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention jieba langdetect\n",
      "Installing collected packages: keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, keras-transformer, whoosh, syntok, langdetect, keras-bert, jieba, fastprogress, cchardet, ktrain\n",
      "Successfully installed cchardet-2.1.7 fastprogress-1.0.3 jieba-0.42.1 keras-bert-0.89.0 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 ktrain-0.33.2 langdetect-1.0.9 syntok-1.4.4 whoosh-2.7.4\n"
     ]
    }
   ],
   "source": [
    "pip install ktrain #Wrapper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63e1407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0882d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fa37d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ktrain\\text\\preprocessor.py:382: UserWarning: The class_names argument is replacing the classes argument. Please update your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t=text.Transformer(model_name, maxlen=500, classes=train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f397005e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 309\n",
      "\t95percentile : 886\n",
      "\t99percentile : 1913\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3d25c4d8be4c13a092a2f88d5c551d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lenovo\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 321\n",
      "\t95percentile : 861\n",
      "\t99percentile : 2155\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr_train=t.preprocess_train(x_train,y_train)\n",
    "pr_test=t.preprocess_test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "351d7574",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=t.get_classifier()\n",
    "learner=ktrain.get_learner(model, train_data=pr_train, val_data=pr_test, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb1c6f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating training for different learning rates... this may take a few moments...\n",
      "Epoch 1/2\n",
      " 12/714 [..............................] - ETA: 1:30:09 - loss: 1.6115 - accuracy: 0.2083"
     ]
    }
   ],
   "source": [
    "learner.lr_find(show_plot=True, max_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4f08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 5e-05...\n",
      "Epoch 1/4\n",
      "714/714 [==============================] - ETA: 0s - loss: 0.5319 - accuracy: 0.8491"
     ]
    }
   ],
   "source": [
    "learner.fit_onecycle(5e-5,4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
